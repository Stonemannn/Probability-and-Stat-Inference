---
title: "Deliverable2: Monte Carlo Error"
author: ' Jiayu Shi'
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    code_folding: hide
    toc: yes
    number_sections: yes
    toc_depth: 3
    toc_float: yes
---

```{r global options, include = FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, cache=TRUE)
```

# Introduction 

Monte Carlo Simulation can be used to estimate parameters like probabilities. The underlying concept is to use randomness to solve problems that might be difficult or impossible to use other approaches. Intuitively, it seems that the degree of error should get smaller as the number of simulation replicates increases. In fact, by the law of large numbers, when the number of replicates is increasing, the simulation error should be decreasing.  
As to **Why the concept is important**, mathematicians, statisticians, and other experts sometimes use Monte Carlo Simulation to estimate probabilities, if there is no relationship between the number of replicates and the simulation error, or if when the number of replicates is increasing, the simulation error isn't decreasing, the estimations they get cannot be recognized as a good alternative to the real probabilities.   
There are some **terminologies** which will be used to identify the error.  

+  $Absolute Error = |\hat{p}-p|$
+  $Relative Error = |\hat{p}-p|/p$

# Methods

In this paragraph, I will perform an experiment simulation that estimates the error for each combination of replicate number ($2^2, 2^3, â€¦, 2^{15}$) and probability ($0.01, 0.05, 0.10, 0.25, 0.50$). Let $\hat{p}$ denote the probability estimated from simulation, and let $p$ denote the true underlying probability.   
The first chunk of code is used to build up a dataframe which includes all the necessary simulation values in it.   
```{r}
library(tidyverse)
#the variable size is used to store the replicate numbers
(output <- expand.grid(
   size = 2^c(2:15)
  ,p = c(0.01, 0.05, 0.10, 0.25, 0.50)
  ,abs_error = NA
  ,rel_error = NA
))
r = 10000 #repeat 10000 times to get the mean value
for (i in 1:nrow(output)) {
  phat <- rbinom(r, output$size[i], output$p[i])/output$size[i] 
  output$abs_error[i] <- mean( abs(phat-output$p[i]))
  output$rel_error[i] <- mean( abs(phat-output$p[i])/output$p[i] )
}

output


```
The second chunk of code is used to show the figure of relationship between **Absolute Error** and **Replicate Numbers**     




  labs(
    x = "size(log_2 scale)",
    y = "Absolute Error"
  ) 
```{r}
ggplot(data=output, mapping = aes(x=log2(size), y= abs_error,  color= as.factor(p)))+
  geom_point() +
  geom_line() +
  labs(
    x = "size(log_2 scale)",
    y = "Absolute Error",
    col ="Probability"
  ) 

```


The third chunk of code is used to show the figure of relationship between **Relative Error** and **Replicate Numbers**   


```{r}
ggplot(data=output, mapping = aes(x=log2(size), y= rel_error,  colour = as.factor(p)))+
  geom_point() +
  geom_line() +
  labs(
    x = "size(log_2 scale)",
    y = "Relative Error",
    color ="Probability"
  ) 
```


# Results
By analyzing and comparing these two figures, we can notice that, at start, when the **replicate numbers** are small, although there is an difference between differently pre-set $p$, as the **replicate numbers** increases to $2^{12}$, both **Errors** are merging to the $0$.

# Conclusions
So the conclusion is that when a simulation's **replicate number** has reached a relatively large number, the estimated probabilty can be used as a good alternative to the real underlying probability.



